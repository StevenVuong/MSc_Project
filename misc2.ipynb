{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "misc2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/StevenVuong/MSc_Project/blob/master/misc2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdzBN1AhkB8-",
        "colab_type": "text"
      },
      "source": [
        "**Goal: Build a joint deeplearning model which trains on ages and genders, to classify that of the fifth batch.** \n",
        "**Then ensemble this with deep learning prediction outputs of our best model to get the final classification**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HffPUoiMkAb4",
        "colab_type": "code",
        "outputId": "1ba5eadd-0358-4a1b-e237-b8caf0cb5029",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Standard imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "# other imports to handle files\n",
        "import os\n",
        "import pickle\n",
        "import csv\n",
        "\n",
        "# deep learning imports\n",
        "from keras.models import Sequential, load_model, Model\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers.convolutional import Convolution3D, MaxPooling3D, Convolution1D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.optimizers import SGD, RMSprop, Adam\n",
        "from keras.utils import np_utils, generic_utils, to_categorical\n",
        "from keras.layers import LeakyReLU, Input, ReLU, concatenate\n",
        "from keras import regularizers\n",
        "\n",
        "# to split our dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# to mount our drive\n",
        "from google.colab import drive"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJGlXqK7j8vD",
        "colab_type": "code",
        "outputId": "ce3e81b6-7c03-4d64-b0a8-3056041023fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "# mount google drive into google colab\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "os.chdir('/content')\n",
        "\n",
        "# go to where we will be working\n",
        "print (os.listdir())\n",
        "os.chdir('gdrive/My Drive/msc_project/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "['.config', 'gdrive', 'sample_data']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzRqVyvgomjT",
        "colab_type": "text"
      },
      "source": [
        "**Run through our batches and train our model after building it**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrA5vdtKpcqi",
        "colab_type": "code",
        "outputId": "da41a487-1ddc-4cb2-ca5e-f319997b7756",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "## Loop through all our total slices and accumulate all the total slices info\n",
        "training_batch_f = os.listdir('stored_batches_trim')[:6]\n",
        "print (training_batch_f)\n",
        "\n",
        "# build ultima total slices info\n",
        "tsi_ultima = []\n",
        "\n",
        "# load the pickle (train with 0 to 6)\n",
        "for tbf in training_batch_f:\n",
        "  with open('stored_batches_trim/'+tbf, 'rb') as f:\n",
        "    total_slices, total_slices_info = pickle.load(f) # stored_batches/total_slices_batch5\n",
        "    \n",
        "    tsi_ultima.extend(total_slices_info)\n",
        "    \n",
        "print (np.shape(tsi_ultima))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['dtotal_slices_batch0.pkl', 'dtotal_slices_batch1.pkl', 'dtotal_slices_batch2.pkl', 'dtotal_slices_batch3.pkl', 'dtotal_slices_batch4.pkl', 'dtotal_slices_batch6.pkl']\n",
            "(620, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6I8sh1rCrmME",
        "colab_type": "code",
        "outputId": "b4829045-da41-4888-c3b8-a371d53bf9e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.shape(tsi_ultima) # use this to train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(620, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qE9O2hmGkBmb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_classification(total_slices_info):\n",
        "    '''get information of patient from total slices info'''\n",
        "    classif = [s[2] for s in total_slices_info]\n",
        "    classif = np.array(to_categorical(classif, 2))\n",
        "    \n",
        "    # now do the same for the sex, 'F' is 0, 'M' is 1\n",
        "    sex = [s[1] for s in total_slices_info]\n",
        "    for i in range(len(sex)):\n",
        "        if sex[i] == 'F':\n",
        "            sex[i] = 0\n",
        "        if sex[i] == 'M':\n",
        "            sex[i] = 1\n",
        "    sex = np.array(to_categorical(sex, 2))\n",
        "    \n",
        "    # finally for age, one hot encode ages 0 to 100 (101 classes then)\n",
        "    ages = [s[3] for s in total_slices_info]\n",
        "    ages = np.array(to_categorical(ages, 101))\n",
        "    \n",
        "    return classif, sex, ages\n",
        "\n",
        "y_values_train, sex_train, ages_train = get_classification(tsi_ultima)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWqqxB8ypBgL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_mlp(dim, regress=False):\n",
        "    '''Create our MLP network'''\n",
        "    model = Sequential()\n",
        "    model.add(Dense(8, input_dim=dim, activation=\"relu\"))\n",
        "    model.add(Dense(2, activation=\"relu\"))\n",
        " \n",
        "    # check to see if the regression node should be added\n",
        "    if regress:\n",
        "        model.add(Dense(1, activation=\"linear\"))\n",
        " \n",
        "    # return our model\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OS2QxNNpHaP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# creds: https://www.puzzlr.org/the-keras-functional-api-five-simple-examples/\n",
        "# Create MLP models\n",
        "mlp_sex = create_mlp(sex_train.shape[1], regress=False)\n",
        "mlp_age = create_mlp(ages_train.shape[1], regress=False)\n",
        "\n",
        "# create the input to our final set of layers as the *output* of both\n",
        "# the MLP and CNN\n",
        "combined_input = concatenate([mlp_sex.output, mlp_age.output])\n",
        "\n",
        "# our final FC layer head will have two dense layers, the final one\n",
        "# being our regression head\n",
        "x = Dense(8, activation=\"relu\")(combined_input)\n",
        "x = Dense(2, activation=\"sigmoid\")(x)\n",
        "\n",
        "# our final model will accept categorical/numerical data on the MLP\n",
        "# input and images on the CNN input, outputting a single value (the\n",
        "# predicted price of the house)\n",
        "as_model = Model(inputs=[mlp_sex.input, mlp_age.input], outputs=x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7wNgZ89trZc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compile our model\n",
        "as_model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(lr=1e-3, decay=1e-3 / 200), \n",
        "              metrics = ['categorical_accuracy']) # decay in Adam..\n",
        "\n",
        "# train the model\n",
        "print(\"training model...\")\n",
        "as_model.fit([sex_train, ages_train], y_values_train, validation_split=0.1, epochs=200, batch_size=205)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4Esb6vfqURV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load our pickle model (ALTERNATIVE)\n",
        "with open('all_mprage_grappa/z_tests/as_model.pkl', 'rb') as f: # also 'total_slices_all.pkl' ## RENAMED 5 TO 7, TESTING IT\n",
        "  as_model = pickle.load(f) # stored_batches/total_slices_batch5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYjNw77Lt7nt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load our pickle batch of data\n",
        "with open('stored_batches_trim/dtotal_slices_batch5.pkl', 'rb') as f: # also 'total_slices_all.pkl' ## RENAMED 5 TO 7, TESTING IT\n",
        "  total_slices_test, total_slices_info_test = pickle.load(f) # stored_batches/total_slices_batch5\n",
        "  \n",
        "# get the test factors\n",
        "y_values_test, sex_test, ages_test = get_classification(total_slices_info_test)\n",
        "\n",
        "# expand the set\n",
        "total_slices_test = np.array(total_slices_test)\n",
        "total_slices_test = np.expand_dims(total_slices_test, axis=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLnxpNkCxFZ1",
        "colab_type": "code",
        "outputId": "c43ad6d6-bec0-4aba-8142-2107e111db22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# test our model against the hidden one\n",
        "score, acc = as_model.evaluate([sex_test, ages_test], y_values_test)\n",
        "\n",
        "print (\"Score: %.2f\" % score) # just by running a deep learning model with the goddamn ages and gender, wtf"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "102/102 [==============================] - 0s 2ms/step\n",
            "Score: 0.98\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_mFSZqfvBCK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## save 98% model \n",
        "# pickle.dump( as_model, open( \"all_mprage_grappa/z_tests/as_model.pkl\", \"wb\" ) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kQ5Mrw5wsVp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "as_preds_train = as_model.predict([sex_train, ages_train]) # this is what we will feed into next model\n",
        "as_preds_test = as_model.predict([sex_test, ages_test]) # this is what we will use when testing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hA2N4vQ7yVEv",
        "colab_type": "text"
      },
      "source": [
        "**Next part, get predictions from model on ages and sex and predictions from images, feed into another deep NN to try to predict the output, then test accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3v84hoBy5AE",
        "colab_type": "code",
        "outputId": "dbd94785-1d55-40e8-dd8b-974afbddb6cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# ALTERNATIVELY: load our cnn_models\n",
        "cnn_model = load_model('all_mprage_grappa/z_tests/models/_all_batches_040.h5') # take 040, best performing one so far"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0620 06:49:10.729431 140591951792000 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYHzkS1kxKWX",
        "colab_type": "code",
        "outputId": "9c2291d5-368c-445e-b9fa-649ad9615177",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "#load batch slices, predict and aggregate scores\n",
        "cnn_train_preds = []\n",
        "\n",
        "# load the pickle (train with 0 to 6)\n",
        "print (training_batch_f)\n",
        "for tbf in training_batch_f:\n",
        "  with open('stored_batches_trim/'+tbf, 'rb') as f:\n",
        "    total_slices, total_slices_info = pickle.load(f) \n",
        "    # predict and aggregate\n",
        "    total_slices = np.array(total_slices)\n",
        "    total_slices = np.expand_dims(total_slices, axis=4)\n",
        "    \n",
        "    # split and predict, too many to handle otherwise and will crash\n",
        "    sub_arrays = np.array_split(total_slices, 50)\n",
        "    \n",
        "    for i in range(len(sub_arrays)):\n",
        "      \n",
        "      sub_array = sub_arrays[i]\n",
        "      cnn_prediction = cnn_model.predict(sub_array)\n",
        "      cnn_train_preds.extend(cnn_prediction)\n",
        "    \n",
        "print (np.shape(cnn_train_preds))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0619 14:07:23.063912 140617590118272 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['dtotal_slices_batch0.pkl', 'dtotal_slices_batch1.pkl', 'dtotal_slices_batch2.pkl', 'dtotal_slices_batch3.pkl', 'dtotal_slices_batch4.pkl', 'dtotal_slices_batch6.pkl']\n",
            "(620, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPaXsBh1NzDc",
        "colab_type": "text"
      },
      "source": [
        "**Now make deep learning framework where we load our cnn train preds, our as train preds and aggregate**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgy_WLVqv1_4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn_train_preds = pickle.load( open( \"all_mprage_grappa/z_tests/cnn_training_preds.pkl\", \"rb\" ) )\n",
        "cnn_train_preds = np.array(cnn_train_preds)\n",
        "\n",
        "as_preds_train = np.array(as_preds_train)\n",
        "\n",
        "y_train = y_values_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJYsnoPcwwue",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_binary(cat_array):\n",
        "  '''Function to convert categorical back to binary values'''\n",
        "  binary_output_array = []\n",
        "  for i in range(len(cat_array)):\n",
        "    binary_output_array.append(np.argmax(cat_array[i]))\n",
        "    \n",
        "  binary_output_array = np.array(binary_output_array)\n",
        "  return binary_output_array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3NgFPpkMq17",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create MLP models\n",
        "mlp_cnn = create_mlp(2, regress=False) # value of 1 for binary, 2 for categorical\n",
        "mlp_as = create_mlp(2, regress=False)\n",
        "\n",
        "# create the input to our final set of layers as the *output* of both\n",
        "# the MLP and CNN\n",
        "combined_input_two = concatenate([mlp_cnn.output, mlp_as.output])\n",
        "\n",
        "# our final FC layer head will have two dense layers, the final one\n",
        "# being our regression head\n",
        "z = Dense(4, activation=\"relu\")(combined_input_two)\n",
        "z = Dropout(0.2)(z)\n",
        "z = Dense(2, activation=\"sigmoid\")(z)\n",
        "\n",
        "# our final model will accept categorical/numerical data on the MLP\n",
        "# input and images on the CNN input, outputting a single value (the\n",
        "# predicted price of the house)\n",
        "combined_model = Model(inputs=[mlp_cnn.input, mlp_as.input], outputs=z)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDKsn3mJSYNR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compile our model\n",
        "combined_model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(lr=1e-3, decay=1e-3 / 200), \n",
        "              metrics = ['categorical_accuracy']) # decay in Adam..\n",
        "\n",
        "# train the model\n",
        "print(\"training model...\")\n",
        "combined_model.fit([cnn_train_preds, as_train_preds], y_values_train, validation_split=0.1, epochs=200)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xx-CqpxPUSPe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pickle.dump( combined_model, open( \"all_mprage_grappa/z_tests/combined_model_binary.pkl\", \"wb\" ) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENTzWL9pTTYR",
        "colab_type": "text"
      },
      "source": [
        "**Load last one and test it out**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "us7wRSU2S4rc",
        "colab_type": "code",
        "outputId": "8d75d78b-e181-4356-89c1-ec52ae33a421",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# get predictions of cnn_model on test data\n",
        "# get predictions of as_model on test data\n",
        "# input these predictions into our combined_model\n",
        "# evaluate these against the actual y-value, pray it is not overfitted..."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(102, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ON_W4qauTeLb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Getting predictions of cnn model on test data\n",
        "\n",
        "# Split into smaller chunks so our GPU can handle it\n",
        "sub_arrays = np.array_split(total_slices_test, 51)\n",
        "\n",
        "cnn_preds_test = []\n",
        "# run through model and test\n",
        "for i in range(len(sub_arrays)):\n",
        "  sub_array = sub_arrays[i]\n",
        "\n",
        "  # got our scoring metric off the back of this too, all in one notebook\n",
        "  cnn_pred = cnn_model.predict(sub_array)\n",
        "  cnn_preds_test.extend(cnn_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsGbpSiXWamH",
        "colab_type": "code",
        "outputId": "e1975af0-ced3-4f73-f6b2-506f137953ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "cm_score, cm_acc = combined_model.evaluate([cnn_preds_test, as_preds_test], y_values_test)\n",
        "\n",
        "print (\"Combined model score: %.2f, and combined model accuracy: %.2f\" % (cm_score, cm_acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "102/102 [==============================] - 0s 129us/step\n",
            "Combined model score: 1.08, and combined model accuracy: 0.59\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRtf-HdCoJI0",
        "colab_type": "text"
      },
      "source": [
        "**Try: XGboosting the training predicted outputs**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZDlLxAzqkaP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyBt5S9aw_Ta",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert everything to binary\n",
        "cnn_train_preds_binary = to_binary(cnn_train_preds)\n",
        "as_train_preds_binary = to_binary(as_preds_train)\n",
        "y_train_binary = to_binary(y_train)\n",
        "\n",
        "cnn_test_preds_binary = to_binary(cnn_preds_test)\n",
        "as_test_preds_binary = to_binary(as_preds_test)\n",
        "y_test_binary = to_binary(y_values_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7vxZoNjxyo_",
        "colab_type": "code",
        "outputId": "81633373-da04-419a-cb91-5b0ddd20e91d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.shape(y_train_binary) # no worky"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(620,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umVR6Q_esX_L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make into a matrix and input this into our space\n",
        "\n",
        "combined_zipped_train = list(zip(cnn_train_preds_binary, as_train_preds_binary))\n",
        "combined_zipped_train = np.array(combined_zipped_train)\n",
        "\n",
        "# fit model with training data\n",
        "xgb_model = XGBClassifier()\n",
        "xgb_model.fit(combined_zipped_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrOAKOxjrZYE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "combined_zipped_test = list(zip(cnn_preds_test, as_preds_test))\n",
        "combined_zipped_test = np.array(combined_zipped_test)\n",
        "\n",
        "y_values_predictions = []\n",
        "for i in range(len(combined_zipped_test)):\n",
        "  cz_test_csr = csr_matrix(combined_zipped_test[i])\n",
        "  xgb_preds = xgb_model.predict(cz_test_csr)\n",
        "  y_values_predictions.append(xgb_preds)\n",
        "  \n",
        "y_values_predictions = np.array(y_values_predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbDhTUzOvcJG",
        "colab_type": "code",
        "outputId": "e2c7e58f-b952-46d8-a175-9bde48e3b6a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "accuracy_score(y_values_test, y_values_predictions, normalize=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIUzf6sUW73T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn_train_preds # train with this as an input\n",
        "as_preds_train # another input\n",
        "y_train # ideal output\n",
        "\n",
        "#test\n",
        "cnn_preds_test\n",
        "as_preds_test\n",
        "y_values_test\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ag8O6PliZPPo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyXxbK0vbB3B",
        "colab_type": "text"
      },
      "source": [
        "To try: reverse classification on each model and feed these in, see how our model holds up. Then do the same for our test and compare"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srl7AdZxbIaG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}