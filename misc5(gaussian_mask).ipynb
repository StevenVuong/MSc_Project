{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "misc5(gaussian_mask).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/StevenVuong/MSc_Project/blob/master/misc5(gaussian_mask).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdGrMIDaDJcp",
        "colab_type": "code",
        "outputId": "75bea06a-c52a-40f7-bb24-a47788ec1230",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# standard imports\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pickle\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "# to mount our drive\n",
        "from google.colab import drive\n",
        "\n",
        "# import keras stuff\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers.convolutional import Convolution3D, MaxPooling3D, Convolution1D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.optimizers import SGD, RMSprop, Adam\n",
        "from keras.utils import np_utils, generic_utils, to_categorical\n",
        "from keras.layers import LeakyReLU\n",
        "from keras import regularizers\n",
        "\n",
        "# to test our dataset\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# for gaussian mask\n",
        "from scipy.ndimage import gaussian_filter"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KA3IVWoiPgZ7",
        "colab_type": "code",
        "outputId": "06899ace-96b2-46f7-df32-4ebc5c598872",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "# mount google drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "os.chdir('/content')\n",
        "\n",
        "# go to where the data is\n",
        "print (os.listdir())\n",
        "os.chdir('gdrive/My Drive/msc_project/all_mprage_grappa')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "['.config', 'gdrive', 'sample_data']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMaJyJS9sqjo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# gets our y-values and converts to keras, one hot encoded outputs\n",
        "def get_y_values(total_slices_info):\n",
        "  \n",
        "  y_values = [s[2] for s in total_slices_info]\n",
        "\n",
        "  y_values = np.array(to_categorical(y_values, 2))\n",
        "  \n",
        "  return y_values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cu2hcccJCgzn",
        "colab_type": "text"
      },
      "source": [
        "**In this notebook we will experiment with a Gaussian mask and/or very few number of 2D slices to make up our 3D imae to see if it works in our classifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_957-mZC-LH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load a batch\n",
        "# Apply gaussian filter\n",
        "# try run through model\n",
        "# test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HT8vRcPCcll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load a batch\n",
        "with open('processed_brains/processed_brains_aug/dbatch0.pkl', 'rb') as f:\n",
        "  total_slices, total_slices_info = pickle.load(f) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SorUuA8MOQhk",
        "colab_type": "code",
        "outputId": "34e26cb4-b089-460d-9f09-ba71f4c0ac6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        }
      },
      "source": [
        "# apply gaussian mask to our images\n",
        "for i in range(len(total_slices[:,:,:,:,0])):\n",
        "  ts = total_slices[i, :, :, :, 0]\n",
        "  for j in range(len(ts)):\n",
        "    s = ts[j, :, :]\n",
        "    ## apply gaussian mask\n",
        "    tg = gaussian_filter(s, sigma=3) # will have to play around with this to get optimal value\n",
        "    ts[j, :, :] = tg\n",
        "  total_slices[i, :, :, :, 0] = ts"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-07880542cbbb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# apply gaussian mask to our images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_slices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_slices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'total_slices' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0fuOLun1U3K",
        "colab_type": "code",
        "outputId": "ece16e5c-1c88-4e93-f623-048928306324",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "total_slices = total_slices[:, 45:115, :, :, :]\n",
        "np.shape(total_slices)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(58, 70, 160, 160, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Oz1DuBNtDzX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get y values\n",
        "y_values = get_y_values(total_slices_info)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScDEAzwNc4qJ",
        "colab_type": "text"
      },
      "source": [
        "**Combine all into a super array**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGMzCe0iJmap",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# write something to get all the slices, process and add to a super array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dm7JJzJNaExl",
        "colab_type": "code",
        "outputId": "ef847034-ca7f-4259-f5e2-f3c301146ed1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# build the first one\n",
        "total_slices_all = []\n",
        "total_info_all = []\n",
        "\n",
        "total_slices_all.append(total_slices)\n",
        "total_info_all.append(y_values)\n",
        "\n",
        "total_slices_all = np.array(total_slices_all)[0]\n",
        "total_info_all = np.array(total_info_all)[0]\n",
        "\n",
        "print (\"Shape of total slices all: %s\" %(np.shape(total_slices_all),))\n",
        "print (\"Shape of total y values all: %s\" %(np.shape(total_info_all),))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of total slices all: (100, 70, 160, 160, 1)\n",
            "Shape of total y values all: (100, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_QNNoI-biL5",
        "colab_type": "code",
        "outputId": "80256d57-dc07-4dc6-a4f0-273380cc3b3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# add on other slices\n",
        "total_slices_all = np.concatenate((total_slices_all, total_slices))\n",
        "total_info_all = np.concatenate((total_info_all, y_values))\n",
        "\n",
        "print (\"Shape of total slices all: %s\" %(np.shape(total_slices_all),))\n",
        "print (\"Shape of total slices all: %s\" %(np.shape(total_info_all),))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of total slices all: (440, 70, 160, 160, 1)\n",
            "Shape of total slices all: (440, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pwAJVbDri-X",
        "colab_type": "text"
      },
      "source": [
        "**Below is one stop integrated cell (super messy) to build our super arrays of sigmified brainslices**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRo5D00GqPfi",
        "colab_type": "code",
        "outputId": "7ffbd762-2d50-454b-95c4-38758a21801c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# just set the sigma value and run\n",
        "sigma_value = 2.5\n",
        "\n",
        "total_slices_all = []\n",
        "total_info_all = []\n",
        "\n",
        "for iii in range(5):\n",
        "  with open('processed_brains/processed_brains_aug/dbatch'+str(iii)+'.pkl', 'rb') as f:\n",
        "    total_slices, total_slices_info = pickle.load(f) \n",
        "    \n",
        "  # apply gaussian mask to our images\n",
        "  for i in range(len(total_slices[:,:,:,:,0])):\n",
        "    ts = total_slices[i, :, :, :, 0]\n",
        "    for j in range(len(ts)):\n",
        "      s = ts[j, :, :]\n",
        "      ## apply gaussian mask\n",
        "      tg = gaussian_filter(s, sigma = sigma_value) # will have to play around with this to get optimal value\n",
        "      ts[j, :, :] = tg\n",
        "    total_slices[i, :, :, :, 0] = ts\n",
        "    \n",
        "  # get the region of slices we want    \n",
        "  total_slices = total_slices[:, 45:115, :, :, :]\n",
        "  \n",
        "  # get y values\n",
        "  y_values = get_y_values(total_slices_info)\n",
        "\n",
        "  # for first run, make that the array and go from there\n",
        "  if (iii == 0):# i has been hijacked\n",
        "    # append to super array\n",
        "    total_slices_all = total_slices\n",
        "    total_info_all = y_values\n",
        "    total_slices_all = np.array(total_slices_all)\n",
        "    total_info_all = np.array(total_info_all)\n",
        "    \n",
        "    # add on the other for non-zero values\n",
        "  if (iii != 0):\n",
        "    total_slices_all = np.concatenate((total_slices_all, total_slices))\n",
        "    total_info_all = np.concatenate((total_info_all, y_values))\n",
        "  \n",
        "print (\"Shape of total slices all: %s\" %(np.shape(total_slices_all),))\n",
        "print (\"Shape of total y values all: %s\" %(np.shape(total_info_all),))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of total slices all: (440, 70, 160, 160, 1)\n",
            "Shape of total y values all: (440, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wn8neJmpp9KZ",
        "colab_type": "text"
      },
      "source": [
        "**Can skip straight to below if want to just use 3sig slices**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuMNPc80AwI8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save as pickle files\n",
        "# pickle.dump( total_slices_all, open( \"gaussian_mask/2dot5sig_slice.p\", \"wb\" ) )\n",
        "# pickle.dump( total_info_all, open( \"gaussian_mask/2dot5sig_info.p\", \"wb\" ) )\n",
        "\n",
        "# load our pickle files now\n",
        "total_slices_all = pickle.load( open( \"gaussian_mask/2dot5sig_slice.p\", \"rb\" ) )\n",
        "total_info_all = pickle.load( open( \"gaussian_mask/2dot5sig_info.p\", \"rb\" ) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Thl0EtsG_TKc",
        "colab_type": "text"
      },
      "source": [
        "**Run our model now**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tG1HWo8TaP4Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split to training and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(total_slices_all, total_info_all, test_size=0.15)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fmozpt5ZtqNk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialise_model():\n",
        "\n",
        "  # compile our model\n",
        "  model = Sequential()\n",
        "  \n",
        "  model.add(Convolution3D(filters=32, kernel_size=3, padding='same', strides=2, input_shape=(70,160,160,1),\n",
        "                          kernel_regularizer=regularizers.l2(0.007), bias_regularizer=regularizers.l2(0.007))) # padding on first one only?\n",
        "  model.add(LeakyReLU(alpha=0.15)) # set to 0.01\n",
        "  model.add(BatchNormalization(momentum=0.2))\n",
        "  model.add(MaxPooling3D(pool_size=2, strides=1, padding='same')) # pool_size=2\n",
        "  # could user he_norm kernel initializer?\n",
        "  \n",
        "  model.add(Convolution3D(filters=64, kernel_size=3, padding='same', strides=2,\n",
        "                          kernel_regularizer=regularizers.l2(0.007), bias_regularizer=regularizers.l2(0.007))) # padding on first one only?\n",
        "  model.add(LeakyReLU(alpha=0.15)) # set to 0.01\n",
        "  model.add(BatchNormalization(momentum=0.2))\n",
        "  model.add(MaxPooling3D(pool_size=2, strides=1, padding='same')) # pool_size=2\n",
        "  \n",
        "  model.add(Convolution3D(filters=128, kernel_size=3, padding='same', strides=2,\n",
        "                          kernel_regularizer=regularizers.l2(0.007), bias_regularizer=regularizers.l2(0.007))) # padding on first one only?\n",
        "  model.add(LeakyReLU(alpha=0.15)) # set to 0.01\n",
        "  model.add(BatchNormalization(momentum=0.2))\n",
        "  model.add(MaxPooling3D(pool_size=2, strides=1, padding='same')) # pool_size=2\n",
        "\n",
        "  model.add(Convolution3D(filters=256, kernel_size=3, padding='same', strides=2,\n",
        "                          kernel_regularizer=regularizers.l2(0.007), bias_regularizer=regularizers.l2(0.007))) # padding on first one only?\n",
        "  model.add(LeakyReLU(alpha=0.15)) # set to 0.01\n",
        "  model.add(BatchNormalization(momentum=0.2))\n",
        "  model.add(MaxPooling3D(pool_size=2, strides=1, padding='same')) # pool_size=2\n",
        "  \n",
        "  model.add(Convolution3D(filters=512, kernel_size=2, padding='same', strides=2,\n",
        "                          kernel_regularizer=regularizers.l2(0.007), bias_regularizer=regularizers.l2(0.007))) # padding on first one only?\n",
        "  model.add(LeakyReLU(alpha=0.15)) # set to 0.01\n",
        "  model.add(BatchNormalization(momentum=0.2))\n",
        "  model.add(MaxPooling3D(pool_size=2, strides=2, padding='same')) # pool_size=2\n",
        "  \n",
        "  model.add(Flatten())\n",
        "   \n",
        "  model.add(Dense(512, kernel_regularizer=regularizers.l2(0.007)))\n",
        "  model.add(LeakyReLU(alpha=0.15)) # set to 0.01\n",
        "  \n",
        "  model.add(Dropout(0.20)) # add dropout to prevent overfitting\n",
        "  \n",
        "  model.add(Dense(64, kernel_regularizer=regularizers.l2(0.007)))\n",
        "  model.add(LeakyReLU(alpha=0.15)) # set to 0.01\n",
        "  \n",
        "  model.add(Dropout(0.35)) # add dropout to prevent overfitting\n",
        "\n",
        "  model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "  model.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy',metrics = ['categorical_accuracy'])\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Q1QChputaQE",
        "colab_type": "code",
        "outputId": "5b35dbdc-fd15-4645-88fe-77972bfcd8f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = initialise_model()\n",
        "model.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0716 00:25:16.252582 140519328597888 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0716 00:25:16.304205 140519328597888 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0716 00:25:16.313429 140519328597888 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0716 00:25:16.467433 140519328597888 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0716 00:25:17.079534 140519328597888 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0716 00:25:17.173813 140519328597888 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0716 00:25:17.188125 140519328597888 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv3d_1 (Conv3D)            (None, 35, 80, 80, 32)    896       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 35, 80, 80, 32)    0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 35, 80, 80, 32)    128       \n",
            "_________________________________________________________________\n",
            "max_pooling3d_1 (MaxPooling3 (None, 35, 80, 80, 32)    0         \n",
            "_________________________________________________________________\n",
            "conv3d_2 (Conv3D)            (None, 18, 40, 40, 64)    55360     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 18, 40, 40, 64)    0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 18, 40, 40, 64)    256       \n",
            "_________________________________________________________________\n",
            "max_pooling3d_2 (MaxPooling3 (None, 18, 40, 40, 64)    0         \n",
            "_________________________________________________________________\n",
            "conv3d_3 (Conv3D)            (None, 9, 20, 20, 128)    221312    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 9, 20, 20, 128)    0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 9, 20, 20, 128)    512       \n",
            "_________________________________________________________________\n",
            "max_pooling3d_3 (MaxPooling3 (None, 9, 20, 20, 128)    0         \n",
            "_________________________________________________________________\n",
            "conv3d_4 (Conv3D)            (None, 5, 10, 10, 256)    884992    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 5, 10, 10, 256)    0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 5, 10, 10, 256)    1024      \n",
            "_________________________________________________________________\n",
            "max_pooling3d_4 (MaxPooling3 (None, 5, 10, 10, 256)    0         \n",
            "_________________________________________________________________\n",
            "conv3d_5 (Conv3D)            (None, 3, 5, 5, 512)      1049088   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)    (None, 3, 5, 5, 512)      0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 3, 5, 5, 512)      2048      \n",
            "_________________________________________________________________\n",
            "max_pooling3d_5 (MaxPooling3 (None, 2, 3, 3, 512)      0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               4719104   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                32832     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)    (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 6,967,682\n",
            "Trainable params: 6,965,698\n",
            "Non-trainable params: 1,984\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFjv02qSudrD",
        "colab_type": "code",
        "outputId": "16acba35-3662-49be-c00c-88ca7b77ac22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "source": [
        "hist = model.fit(x=X_train, y=y_train, batch_size = 15, epochs=500, verbose=1, shuffle=True,validation_split=0.05)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0716 00:25:17.778263 140519328597888 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 355 samples, validate on 19 samples\n",
            "Epoch 1/500\n",
            "355/355 [==============================] - 34s 97ms/step - loss: 13.6145 - categorical_accuracy: 0.5465 - val_loss: 12.6995 - val_categorical_accuracy: 0.5789\n",
            "Epoch 2/500\n",
            "355/355 [==============================] - 20s 58ms/step - loss: 12.9594 - categorical_accuracy: 0.5127 - val_loss: 12.5082 - val_categorical_accuracy: 0.3684\n",
            "Epoch 3/500\n",
            "355/355 [==============================] - 20s 58ms/step - loss: 12.5412 - categorical_accuracy: 0.5972 - val_loss: 12.3801 - val_categorical_accuracy: 0.3684\n",
            "Epoch 4/500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K31anGmhiu95",
        "colab_type": "text"
      },
      "source": [
        "**Diagnostics**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4G3Wa0vtjSt0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###############################################################################################\n",
        "## LOAD DIAGNOSTICS ##\n",
        "###############################################################################################\n",
        "# X_train, X_test, y_train, y_test, model, hist, score, acc =  pickle.load( open( \"gaussian_mask/3sig_diagnostics.p\", \"rb\" ) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nhjX8L1uqUJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score, acc = model.evaluate(X_test, y_test)\n",
        "print (\"The score of the model: %f, The mean accuracy of the model: %f\" % (score, acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zw0VH4nQgs0o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://machinelearningmastery.com/display-deep-learning-model-training-history-in-keras/\n",
        "# list all data in history\n",
        "print(hist.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(hist.history['categorical_accuracy'])\n",
        "plt.plot(hist.history['val_categorical_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzQxddjwgHT_",
        "colab_type": "text"
      },
      "source": [
        "**Save train set, test set, score, accuracy and history**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGYQOjK6gB0i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###############################################################################################\n",
        "# SAVE DIAGNOSTICS #\n",
        "###############################################################################################\n",
        "all_diagnostics = [X_train, X_test, y_train, y_test, model, hist, score, acc]\n",
        "pickle.dump( all_diagnostics, open( \"gaussian_mask/2dot5sig_diagnostics.p\", \"wb\" ) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWPy8b1UtPOJ",
        "colab_type": "text"
      },
      "source": [
        "**Visualise brains**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRQtZcurPrMy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from ipywidgets import interact, interactive, fixed, interact_manual\n",
        "import ipywidgets as widgets # interactive plots\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "slice_ex = total_slices[50, :, :, :, 0]\n",
        "def g(i): # basic slideshow plot to get an idea of the effectiveness of the mask itself\n",
        "    plt.figure(figsize=(15,8)) # make plot larger\n",
        "    plt.imshow(slice_ex[i])\n",
        "    plt.show()\n",
        "    # plt.imsave('figures/axial_processed2.png', slice_ex[i])\n",
        "    return None\n",
        "\n",
        "interact(g, i=widgets.IntSlider(min=0,max=(len(slice_ex)-1),step=1,value=0)); # 140 for axial view. 88 for sag"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFTWTM-TQBwL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}