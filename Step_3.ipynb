{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Step 3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/StevenVuong/MSc_Project/blob/master/Step_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbY9q9o17l1b",
        "colab_type": "text"
      },
      "source": [
        "**This notebook is for analytics**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFgIgPxR7kTD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "82d726e8-cba6-4658-d5f9-ebea62f7f0f9"
      },
      "source": [
        "# standard imports\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pickle\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "# to mount our drive\n",
        "from google.colab import drive\n",
        "\n",
        "# import keras stuff\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers.convolutional import Convolution3D, MaxPooling3D, Convolution1D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.optimizers import SGD, RMSprop, Adam\n",
        "from keras.utils import np_utils, generic_utils, to_categorical\n",
        "from keras.layers import LeakyReLU\n",
        "from keras import regularizers\n",
        "\n",
        "# to test our dataset\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYzck96k7qkd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "2e066545-3050-486a-b65d-92ae4f95d944"
      },
      "source": [
        "# mount google drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "os.chdir('/content')\n",
        "\n",
        "# go to where the data is\n",
        "print (os.listdir())\n",
        "os.chdir('gdrive/My Drive/msc_project/all_mprage_grappa')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "['.config', 'gdrive', 'sample_data']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MxFYHbK7160",
        "colab_type": "text"
      },
      "source": [
        "**Get our dataframe**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrAh1PhE7uRg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stored_name = '00_v0'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbxO9mG-8382",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# read metrics file, format: [val_loss,val_acc, train_loss, train_acc, test_loss, test_acc]\n",
        "metrics_df = pd.read_csv('stored_metrics_v2/metrics' +stored_name+'.csv', header=None)\n",
        "\n",
        "# relabel headers\n",
        "metrics_df.columns = ['val_loss', 'val_acc', 'train_loss', 'train_acc']\n",
        "metrics_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyuRXkpr844k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# aggregate so we have the averages of each batch (trains on 1 now and tests on 1)\n",
        "batch_mean_df = metrics_df.groupby(np.arange(len(metrics_df))//3).mean()\n",
        "\n",
        "# only want to take the last number of epochs we trained for\n",
        "batch_mean_df = batch_mean_df.tail(30)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxYtJzE89FRY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get the final output (model at end)\n",
        "batch_mean_df.iloc[-1,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9ExYzLv9IW0",
        "colab_type": "text"
      },
      "source": [
        "**Plot noise and loss for train/test sets** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQ6FWkcU9HPE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plotting the accuracy\n",
        "plt.plot(batch_mean_df.val_acc.values, label='val_acc', ls='-')\n",
        "plt.plot(batch_mean_df.train_acc.values, label='train_acc', ls='-.')\n",
        "\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Accuracy ')\n",
        "\n",
        "plt.legend(loc='best')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tU0GuN0v9Rh0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plotting the loss\n",
        "plt.plot(batch_mean_df.val_loss.values, label='val_loss', ls='-')\n",
        "plt.plot(batch_mean_df.train_loss.values, label='train_loss', ls='-.')\n",
        "\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss')\n",
        "\n",
        "plt.legend(loc='best')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNCFBGcz9T-J",
        "colab_type": "text"
      },
      "source": [
        "**Load the model with the final dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yS7cSo1A9St_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load our pickle batch of data\n",
        "with open('stored_batches/batch3.pkl', 'rb') as f: # also 'total_slices_all.pkl' ## RENAMED 5 TO 7, TESTING IT\n",
        "  total_slices, total_slices_info = pickle.load(f) # stored_batches/total_slices_batch5\n",
        "  \n",
        "# load our model\n",
        "model = load_model('stored_models/model'+stored_name+'.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJ0z2Trb_jhC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# gets our y-values and converts to keras, one hot encoded outputs\n",
        "def get_y_values(total_slices_info):\n",
        "  \n",
        "  y_values = [s[2] for s in total_slices_info]\n",
        "\n",
        "  y_values = np.array(to_categorical(y_values, 2))\n",
        "  \n",
        "  return y_values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5CEIOf__lCz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.unique([s[2] for s in total_slices_info], return_counts=True) # look at distribution of patients"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttI7uyer_mIp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get y values\n",
        "y_values = get_y_values(total_slices_info)\n",
        "\n",
        "# turn into a numpy array\n",
        "total_slices = np.array(total_slices)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amY722ym_oT9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Build function to load and build score on the fly then aggregate\n",
        "\n",
        "# Split into smaller chunks so our GPU can handle it\n",
        "sub_arrays = np.split(total_slices[:100], 20)\n",
        "sub_y_values = np.split(y_values[:100], 20)\n",
        "\n",
        "score_sum = []\n",
        "acc_sum = []\n",
        "# run through model and test\n",
        "for i in range(len(sub_arrays)):\n",
        "  sub_array = sub_arrays[i]\n",
        "  sub_y_value = sub_y_values[i]\n",
        "  \n",
        "  score, acc = model.evaluate(sub_array, sub_y_value)\n",
        "  score_sum.append(score)\n",
        "  acc_sum.append(acc)\n",
        "  \n",
        "# get average values\n",
        "mean_score = np.mean(score_sum)\n",
        "mean_acc = np.mean(acc_sum)\n",
        "\n",
        "print (\"The mean score of the model: %f, The mean accuracy of the model: %f\" % (mean_score, acc))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}