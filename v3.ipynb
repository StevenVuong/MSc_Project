{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "v3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/StevenVuong/MSc_Project/blob/master/v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMtiAm8dsTZX",
        "colab_type": "code",
        "outputId": "0053dbc7-5eec-411d-b472-f0a4c495f080",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        }
      },
      "source": [
        "# install dependencies\n",
        "!pip install deepbrain; # semi-colon to hide the output\n",
        "!pip install pydicom;"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: deepbrain in /usr/local/lib/python3.6/dist-packages (0.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (from deepbrain) (0.15.0)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.6/dist-packages (from deepbrain) (2.3.3)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (from deepbrain) (1.13.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->deepbrain) (1.0.3)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->deepbrain) (1.3.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->deepbrain) (2.3)\n",
            "Requirement already satisfied: imageio>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image->deepbrain) (2.4.1)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->deepbrain) (4.3.0)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->deepbrain) (3.0.3)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.6/dist-packages (from nibabel->deepbrain) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.7.1 in /usr/local/lib/python3.6/dist-packages (from nibabel->deepbrain) (1.16.4)\n",
            "Requirement already satisfied: bz2file in /usr/local/lib/python3.6/dist-packages (from nibabel->deepbrain) (0.98)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->deepbrain) (0.8.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->deepbrain) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow->deepbrain) (3.7.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow->deepbrain) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow->deepbrain) (0.33.4)\n",
            "Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->deepbrain) (1.13.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->deepbrain) (0.2.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow->deepbrain) (1.0.7)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow->deepbrain) (0.7.1)\n",
            "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->deepbrain) (1.13.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow->deepbrain) (1.0.9)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image->deepbrain) (4.4.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.3.0->scikit-image->deepbrain) (0.46)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->deepbrain) (2.5.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->deepbrain) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->deepbrain) (2.4.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->deepbrain) (1.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow->deepbrain) (41.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow->deepbrain) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow->deepbrain) (0.15.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow->deepbrain) (2.8.0)\n",
            "Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow->deepbrain) (3.0.5)\n",
            "Requirement already satisfied: pydicom in /usr/local/lib/python3.6/dist-packages (1.2.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0rBEvF98fWW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import os\n",
        "import pydicom\n",
        "import pickle\n",
        "from deepbrain import Extractor\n",
        "import nibabel as nb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vThwOxSsZcG",
        "colab_type": "code",
        "outputId": "0994810d-05f1-4aac-ce5f-4d7352671dcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# mount google drive into google colab\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# go to where the data is\n",
        "print (os.listdir())\n",
        "os.chdir('gdrive/My Drive/msc_project')\n",
        "os.listdir()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "['.config', 'gdrive', 'sample_data']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['t1_scan',\n",
              " 'T1_SAG_SIEMEN_3T_CLEAN_5_29_2019.csv',\n",
              " 'T1_SAG_SIEMEN_3T_CLEAN_1',\n",
              " 'T1_SAG_SIEMEN_3T_CLEAN_5_29_2019.gsheet',\n",
              " 'T1_SAG_SIEMEN_3T_CLEAN',\n",
              " 'loaded_slices',\n",
              " 'trained_model']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_Rz2-kfsp1i",
        "colab_type": "code",
        "outputId": "8ca31c1c-90b9-4086-a2b7-8b58b0e00ba2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "# https://www.kaggle.com/sentdex/first-pass-through-data-w-3d-convnet\n",
        "patients_file_dir = 'T1_SAG_SIEMEN_3T_CLEAN'\n",
        "\n",
        "patients = os.listdir(patients_file_dir) # get all patients ID's in scan\n",
        "patient_df = pd.read_csv('T1_SAG_SIEMEN_3T_CLEAN_5_29_2019.csv') # get dataframe too to cross reference\n",
        "\n",
        "patient_df.head() # so we have a dataframe of our patients' data"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Image Data ID</th>\n",
              "      <th>Subject</th>\n",
              "      <th>Group</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>Visit</th>\n",
              "      <th>Modality</th>\n",
              "      <th>Description</th>\n",
              "      <th>Type</th>\n",
              "      <th>Acq Date</th>\n",
              "      <th>Format</th>\n",
              "      <th>Downloaded</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1130198</td>\n",
              "      <td>75422</td>\n",
              "      <td>GenCohort Unaff</td>\n",
              "      <td>M</td>\n",
              "      <td>73</td>\n",
              "      <td>1</td>\n",
              "      <td>MRI</td>\n",
              "      <td>MPRAGE GRAPPA</td>\n",
              "      <td>Original</td>\n",
              "      <td>11/13/2018</td>\n",
              "      <td>DCM</td>\n",
              "      <td>5/07/2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1130190</td>\n",
              "      <td>75414</td>\n",
              "      <td>GenCohort Unaff</td>\n",
              "      <td>F</td>\n",
              "      <td>73</td>\n",
              "      <td>1</td>\n",
              "      <td>MRI</td>\n",
              "      <td>Sag MPRAGE GRAPPA</td>\n",
              "      <td>Original</td>\n",
              "      <td>12/13/2018</td>\n",
              "      <td>DCM</td>\n",
              "      <td>4/24/2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1130191</td>\n",
              "      <td>75414</td>\n",
              "      <td>GenCohort Unaff</td>\n",
              "      <td>F</td>\n",
              "      <td>73</td>\n",
              "      <td>1</td>\n",
              "      <td>MRI</td>\n",
              "      <td>Sag MPRAGE GRAPPA</td>\n",
              "      <td>Original</td>\n",
              "      <td>12/13/2018</td>\n",
              "      <td>DCM</td>\n",
              "      <td>4/24/2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1125041</td>\n",
              "      <td>74375</td>\n",
              "      <td>GenCohort Unaff</td>\n",
              "      <td>F</td>\n",
              "      <td>59</td>\n",
              "      <td>1</td>\n",
              "      <td>MRI</td>\n",
              "      <td>MPRAGE_GRAPPA</td>\n",
              "      <td>Original</td>\n",
              "      <td>9/06/2018</td>\n",
              "      <td>DCM</td>\n",
              "      <td>4/24/2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1003469</td>\n",
              "      <td>72138</td>\n",
              "      <td>GenCohort Unaff</td>\n",
              "      <td>F</td>\n",
              "      <td>55</td>\n",
              "      <td>1</td>\n",
              "      <td>MRI</td>\n",
              "      <td>MPRAGE GRAPPA</td>\n",
              "      <td>Original</td>\n",
              "      <td>2/19/2018</td>\n",
              "      <td>DCM</td>\n",
              "      <td>4/24/2019</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Image Data ID  Subject            Group  ...    Acq Date  Format  Downloaded\n",
              "0        1130198    75422  GenCohort Unaff  ...  11/13/2018     DCM   5/07/2019\n",
              "1        1130190    75414  GenCohort Unaff  ...  12/13/2018     DCM   4/24/2019\n",
              "2        1130191    75414  GenCohort Unaff  ...  12/13/2018     DCM   4/24/2019\n",
              "3        1125041    74375  GenCohort Unaff  ...   9/06/2018     DCM   4/24/2019\n",
              "4        1003469    72138  GenCohort Unaff  ...   2/19/2018     DCM   4/24/2019\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12VGP3E9Cplw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Map GenCohort to regular PD and Controls\n",
        "patient_df['Group'] = patient_df['Group'].replace({'GenCohort PD':'PD', 'GenCohort Unaff':'Control'})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W13cQHKlcER1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_grappa_dir(path):\n",
        "  # get the file ending with 'GRAPPA', would need to accomodate this for grappa also\n",
        "  returning_path = None\n",
        "  for next_path in os.listdir(path):\n",
        "    if (next_path.split(\"_\")[-1] == 'GRAPPA'): # for the t1 weighted\n",
        "      returning_path = next_path\n",
        "      return returning_path\n",
        "\n",
        "def get_dcm_s(path):\n",
        "  # get the path beginning with S, so doesn't clash with GZ File\n",
        "  for next_path in os.listdir(path):\n",
        "    if (next_path[0] == 'S'):\n",
        "      return next_path\n",
        "\n",
        "def get_img_no(path):\n",
        "  # get the image identification numberm any image will do for this so take first\n",
        "  image_number = None\n",
        "  for image_file in os.listdir(path):\n",
        "    image_number = int(image_file.split(\"_\")[-1][1:-4]) # index to get the ID\n",
        "   \n",
        "  return image_number\n",
        "\n",
        "def filename_sort(filename):\n",
        "    \n",
        "    # split by underlines and delimiter\n",
        "    split_line = filename.split(\"_\")\n",
        "    int_return = int(split_line[-3])\n",
        "    \n",
        "    return int_return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sl5PHrHNON1i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_slices(patient):\n",
        "  '''For any given patient, returns the slices for them'''\n",
        "  try:\n",
        "    # label = patient_df.get_value(patient, 'Subject') # cannot go by patient, must get the ID\n",
        "    path = cwd + '/' + patients_file_dir + '/' + patient # get to the GRAPPA \n",
        "    path = path + '/' + get_grappa_dir(path)\n",
        "    path = path + '/' + os.listdir(path)[-1] # get the most recent scan for patient\n",
        "    path = path + '/' + get_dcm_s(path)\n",
        "\n",
        "    # get information related around the image\n",
        "    image_number = get_img_no(path)\n",
        "    image_row = patient_df.loc[patient_df['Image Data ID'] == image_number] # relate to df\n",
        "    image_sex = image_row.Sex.values[0]\n",
        "    image_group = image_row.Group.values[0]\n",
        "    image_age = image_row.Age.values[0]\n",
        "\n",
        "    # create image object and append to total info\n",
        "    image_info = [image_number, image_sex, image_group, image_age]\n",
        "\n",
        "    # print (\"Sex: %s, Age: %s, Group: %s \" % (image_sex, image_age, image_group))\n",
        "\n",
        "    # get files and sort them in order\n",
        "    dcm_files = os.listdir(path)\n",
        "    dcm_files = sorted(dcm_files, key=lambda filename: filename_sort(filename)) # some have length 3\n",
        "\n",
        "    slices = []\n",
        "    # loop through slices and build the array\n",
        "    for dcm_file in dcm_files:\n",
        "      path_to_file = path + '/' + dcm_file\n",
        "      slices.append(pydicom.read_file(path_to_file).pixel_array)\n",
        "    slices = np.array(slices)[15:175, :, :]\n",
        "    \n",
        "    return slices, image_info\n",
        " \n",
        "  except Exception as e:\n",
        "    print (\"No File Found: %s\" % str(e))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjlKpUkxtEM8",
        "colab_type": "code",
        "outputId": "f8cc1288-c480-44fa-b9e2-02f4d0439e03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        }
      },
      "source": [
        "cwd = os.getcwd()\n",
        "print (\"Current Working Dir: %s \" % cwd)\n",
        "\n",
        "total_slices = [] # build all the slices\n",
        "counter = 0\n",
        "\n",
        "for patient in patients[:20]:\n",
        "  slices, image_info = get_slices(patient) # grab slices for a patient\n",
        "\n",
        "  if (np.shape(slices)[0] == 160): # only add if slices are 160\n",
        "    total_slices.append([slices, image_info])\n",
        "\n",
        "    # print for counter\n",
        "    counter = counter+1\n",
        "    print (\"%d slices loaded\" % counter)\n",
        "\n",
        "    print (np.shape(slices)) # each patient has different number of slices, trim it to [15:175, 30:230, 30:230]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Current Working Dir: /content/gdrive/My Drive/msc_project \n",
            "1 slices loaded\n",
            "(160, 256, 240)\n",
            "2 slices loaded\n",
            "(160, 256, 240)\n",
            "3 slices loaded\n",
            "(160, 256, 240)\n",
            "4 slices loaded\n",
            "(160, 256, 240)\n",
            "5 slices loaded\n",
            "(160, 256, 240)\n",
            "6 slices loaded\n",
            "(160, 256, 240)\n",
            "7 slices loaded\n",
            "(160, 256, 240)\n",
            "8 slices loaded\n",
            "(160, 256, 240)\n",
            "9 slices loaded\n",
            "(160, 256, 240)\n",
            "10 slices loaded\n",
            "(160, 256, 240)\n",
            "11 slices loaded\n",
            "(160, 256, 240)\n",
            "12 slices loaded\n",
            "(160, 256, 240)\n",
            "13 slices loaded\n",
            "(160, 256, 240)\n",
            "14 slices loaded\n",
            "(160, 256, 240)\n",
            "15 slices loaded\n",
            "(160, 256, 240)\n",
            "16 slices loaded\n",
            "(160, 256, 240)\n",
            "17 slices loaded\n",
            "(160, 256, 240)\n",
            "18 slices loaded\n",
            "(160, 256, 240)\n",
            "19 slices loaded\n",
            "(160, 256, 240)\n",
            "20 slices loaded\n",
            "(160, 256, 240)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0Um7yP1Qpw1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save the loaded slices\n",
        "# with open('loaded_slices', \"wb\") as f:\n",
        "    # pickle.dump(total_slices, f)   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdeJlFycRjg2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# total_slices = pickle.load( open( \"loaded_slices\", \"rb\" ) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muOEqm-mSaKZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def process_slice(total_slice):\n",
        "  # deal with mixed slice information\n",
        "  slices = total_slice[0]\n",
        "  \n",
        "  # transform into axial view\n",
        "  slice_axial = slices.transpose((1,2,0))\n",
        "  \n",
        "  # initialise skull stripper\n",
        "  ext = Extractor()\n",
        "\n",
        "  # get probability of part of image being brain tissue or not\n",
        "  prob = ext.run(slice_axial)\n",
        "  mask = prob > 1e-3 # mask can be obtained as:\n",
        "  slice_axial[~mask] = 0 # apply mask\n",
        "  \n",
        "  slice_axial = slice_axial[30:230, 30:230, :] # trim blank ones\n",
        "  \n",
        "  # flip images and add to total processed arrays\n",
        "  flipped_slices = [np.flip(sl,1) for sl in slice_axial]\n",
        "  \n",
        "  return slice_axial, flipped_slices, total_slice[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Aw3M48BuCvj",
        "colab_type": "code",
        "outputId": "a9675765-c5b9-44e8-93aa-7d21a9004d98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "total_slices_processed = []\n",
        "slice_info = []\n",
        "\n",
        "for total_slice in total_slices:\n",
        "\n",
        "  # process each slice individually\n",
        "  slice_axial, flipped_slices, sl_info = process_slice(total_slice)\n",
        "  \n",
        "  # add multiple at once\n",
        "  slice_info.extend((sl_info, sl_info))\n",
        "  total_slices_processed.extend((slice_axial, flipped_slices))\n",
        "  \n",
        "print (\"Example Shape: %s\" % (np.shape(total_slices_processed[0]),) )\n",
        "\n",
        "print (\"Example Info: %s \" % slice_info[0])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deepbrain/extractor.py:19: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.gfile.GFile.\n",
            "Example Shape: (200, 200, 160)\n",
            "Example Info: [498885, 'F', 'PD', 54] \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2f2Eu3iV2Lws",
        "colab_type": "code",
        "outputId": "2dfd164d-8e97-4e3d-cb22-1dd58a7447c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "total_slices_processed = np.array(total_slices_processed) # turn into array\n",
        "total_slices_processed = np.expand_dims(total_slices_processed, axis=4) # expand dimensions\n",
        "\n",
        "np.shape(total_slices_processed)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40, 200, 200, 160, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hZTuCRnAiUz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# need to build the y-data set (PD or Healthy)\n",
        "# then split into test and training set\n",
        "# then try run through a basic model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUTUGaL3Ku3t",
        "colab_type": "code",
        "outputId": "e6cb7e25-dec3-4912-908a-7f47f7b4fb7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "# build y-outputs\n",
        "diagnosis = [s[2] for s in slice_info] # we got our y-values\n",
        "diagnosis = [1 if s=='PD' else s for s in diagnosis]\n",
        "diagnosis = [0 if s=='Control' else s for s in diagnosis]\n",
        "\n",
        "y_output = to_categorical(diagnosis, 2) # convert to something categorical with keras util\n",
        "y_output = np.array(y_output)\n",
        "\n",
        "print (y_output[:5])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLg2r-q79cPN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "d95f0c39-6768-4208-8fa7-f5b3c4e04389"
      },
      "source": [
        "# get distribution of our outputs, to test if our results are better than random \n",
        "distribution_array = np.unique(diagnosis, return_counts=True)\n",
        "percentage_control = distribution_array[1][0]/np.sum(distribution_array[1])*100\n",
        "\n",
        "print (\"Percentage Control: %f%%\" % percentage_control)\n",
        "print (\"Percentage Healthy: %f%%\" % (100-percentage_control))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Percentage Control: 25.000000%\n",
            "Percentage Healthy: 75.000000%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxElWmE4SbU7",
        "colab_type": "code",
        "outputId": "c64756ab-f72e-43d9-9c4e-660b7b754c80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# split into training and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(total_slices_processed, y_output, test_size=0.2, shuffle=True)\n",
        "\n",
        "np.shape(X_train)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 200, 200, 160, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQKeVRq-Uowv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers.convolutional import Convolution3D, MaxPooling3D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.optimizers import SGD, RMSprop, Adam\n",
        "from keras.utils import np_utils, generic_utils\n",
        "from keras.layers import LeakyReLU"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjXpitscUqMu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "f95a387d-a955-481a-a8b4-6095df8bac90"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Convolution3D(filters=8, kernel_size=2, strides=1, padding='same', input_shape=(200,200,160,1))) # or should activation be linear?\n",
        "model.add(LeakyReLU(alpha=0.01)) # set to 0.01\n",
        "model.add(MaxPooling3D())\n",
        "\n",
        "model.add(Convolution3D(filters=16, kernel_size=2, strides=1, padding='same'))\n",
        "model.add(LeakyReLU(alpha=0.01)) \n",
        "model.add(MaxPooling3D())\n",
        "\n",
        "model.add(Convolution3D(filters=32, kernel_size=3, strides=1, padding='same'))\n",
        "model.add(LeakyReLU(alpha=0.01))\n",
        "model.add(MaxPooling3D())\n",
        "\n",
        "model.add(Convolution3D(filters=64, kernel_size=3, strides=1, padding='same'))\n",
        "model.add(LeakyReLU(alpha=0.01))\n",
        "model.add(MaxPooling3D())\n",
        "\n",
        "model.add(Convolution3D(filters=128, kernel_size=4, strides=1, padding='same'))\n",
        "model.add(LeakyReLU(alpha=0.01))\n",
        "model.add(MaxPooling3D())\n",
        "\n",
        "model.add(Convolution3D(filters=256, kernel_size=4, strides=1, padding='same'))\n",
        "model.add(LeakyReLU(alpha=0.01))\n",
        "model.add(MaxPooling3D())\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(LeakyReLU(alpha=0.01))\n",
        "\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer=Adam(lr=0.00005), loss='categorical_crossentropy',metrics = ['accuracy']) # metrics=['categorical_accuracy']"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiAHKsHu60Zd",
        "colab_type": "code",
        "outputId": "3454fc8d-57cb-4979-b3f9-452d6407d150",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 890
        }
      },
      "source": [
        "# optimising with: https://towardsdatascience.com/hyperparameter-optimization-with-keras-b82e6364ca53\n",
        "print (model.summary())"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv3d_1 (Conv3D)            (None, 200, 200, 160, 8)  72        \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 200, 200, 160, 8)  0         \n",
            "_________________________________________________________________\n",
            "max_pooling3d_1 (MaxPooling3 (None, 100, 100, 80, 8)   0         \n",
            "_________________________________________________________________\n",
            "conv3d_2 (Conv3D)            (None, 100, 100, 80, 16)  1040      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 100, 100, 80, 16)  0         \n",
            "_________________________________________________________________\n",
            "max_pooling3d_2 (MaxPooling3 (None, 50, 50, 40, 16)    0         \n",
            "_________________________________________________________________\n",
            "conv3d_3 (Conv3D)            (None, 50, 50, 40, 32)    13856     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 50, 50, 40, 32)    0         \n",
            "_________________________________________________________________\n",
            "max_pooling3d_3 (MaxPooling3 (None, 25, 25, 20, 32)    0         \n",
            "_________________________________________________________________\n",
            "conv3d_4 (Conv3D)            (None, 25, 25, 20, 64)    55360     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 25, 25, 20, 64)    0         \n",
            "_________________________________________________________________\n",
            "max_pooling3d_4 (MaxPooling3 (None, 12, 12, 10, 64)    0         \n",
            "_________________________________________________________________\n",
            "conv3d_5 (Conv3D)            (None, 12, 12, 10, 128)   524416    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)    (None, 12, 12, 10, 128)   0         \n",
            "_________________________________________________________________\n",
            "max_pooling3d_5 (MaxPooling3 (None, 6, 6, 5, 128)      0         \n",
            "_________________________________________________________________\n",
            "conv3d_6 (Conv3D)            (None, 6, 6, 5, 256)      2097408   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)    (None, 6, 6, 5, 256)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling3d_6 (MaxPooling3 (None, 3, 3, 2, 256)      0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 4608)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               2359808   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2)                 1026      \n",
            "=================================================================\n",
            "Total params: 5,052,986\n",
            "Trainable params: 5,052,986\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPrbqZh7FNqh",
        "colab_type": "code",
        "outputId": "0890a1f3-fc94-44c4-eb53-6111d7abba1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "model.fit(x=X_train, y=y_train, batch_size=5, epochs=5, verbose=1,\n",
        "          validation_data=(X_test, y_test), shuffle=True)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 32 samples, validate on 8 samples\n",
            "Epoch 1/5\n",
            "32/32 [==============================] - 20s 610ms/step - loss: 4.6067 - acc: 0.6250 - val_loss: 2.0148 - val_acc: 0.8750\n",
            "Epoch 2/5\n",
            "32/32 [==============================] - 4s 118ms/step - loss: 4.5332 - acc: 0.7188 - val_loss: 2.0148 - val_acc: 0.8750\n",
            "Epoch 3/5\n",
            "32/32 [==============================] - 4s 118ms/step - loss: 4.5332 - acc: 0.7188 - val_loss: 2.0148 - val_acc: 0.8750\n",
            "Epoch 4/5\n",
            "32/32 [==============================] - 4s 119ms/step - loss: 4.5332 - acc: 0.7188 - val_loss: 2.0148 - val_acc: 0.8750\n",
            "Epoch 5/5\n",
            "32/32 [==============================] - 4s 119ms/step - loss: 4.5332 - acc: 0.7188 - val_loss: 2.0148 - val_acc: 0.8750\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f35faeab7b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2taENt9fd5f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save the trained models to evaluate in future (with validation set?)\n",
        "with open('model', \"wb\") as f:\n",
        "    pickle.dump(model, f)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXqdPjxVghsu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "outputId": "6eb3172d-e330-420e-c5e2-3644866e5252"
      },
      "source": [
        "# load our model\n",
        "total_slices = pickle.load( open( \"trained_model\", \"rb\" ) )"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "EOFError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-3b25cfcb4f8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtotal_slices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"trained_model\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mEOFError\u001b[0m: Ran out of input"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1H__27JiltF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://github.com/MinhazPalasara/keras/blob/master/examples/shapes_3d_cnn.py\n",
        "score = model.evaluate(X_test, y_test, batch_size=None)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flSVXwCCnz_S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.shape(np.squeeze(total_slices_processed, axis=4))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4IfnRuglX2K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from ipywidgets import interact, interactive, fixed, interact_manual\n",
        "import ipywidgets as widgets # interactive plots\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "total_slices_processed = np.squeeze(total_slices_processed, axis=4)\n",
        "def g(i): # basic slideshow plot to get an idea of the effectiveness of the mask itself\n",
        "    plt.figure(figsize=(15,8)) # make plot larger\n",
        "    plt.imshow(total_slices_processed[1][i])\n",
        "    plt.show()\n",
        "    return None\n",
        "  \n",
        "interact(g, i=widgets.IntSlider(min=0,max=(len(total_slices_processed[1])-1),step=1,value=65)); # plots our axial view, this is it"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHNUj5XQs-0L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}