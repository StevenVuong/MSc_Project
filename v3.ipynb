{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "v3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/StevenVuong/MSc_Project/blob/master/v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMtiAm8dsTZX",
        "colab_type": "code",
        "outputId": "3978f3cd-63e6-4f9f-c6c4-19270ffc9535",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        }
      },
      "source": [
        "# install dependencies\n",
        "!pip install deepbrain; # semi-colon to hide the output\n",
        "!pip install pydicom;"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: deepbrain in /usr/local/lib/python3.6/dist-packages (0.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (from deepbrain) (0.15.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (from deepbrain) (1.13.1)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.6/dist-packages (from deepbrain) (2.3.3)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->deepbrain) (1.0.3)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->deepbrain) (2.3)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->deepbrain) (3.0.3)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->deepbrain) (4.3.0)\n",
            "Requirement already satisfied: imageio>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image->deepbrain) (2.4.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->deepbrain) (1.3.0)\n",
            "Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->deepbrain) (1.13.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->deepbrain) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow->deepbrain) (1.15.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->deepbrain) (1.12.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow->deepbrain) (0.33.4)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow->deepbrain) (0.7.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow->deepbrain) (1.0.7)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow->deepbrain) (3.7.1)\n",
            "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->deepbrain) (1.13.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow->deepbrain) (1.16.4)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow->deepbrain) (1.0.9)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->deepbrain) (0.8.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->deepbrain) (0.2.2)\n",
            "Requirement already satisfied: bz2file in /usr/local/lib/python3.6/dist-packages (from nibabel->deepbrain) (0.98)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image->deepbrain) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->deepbrain) (2.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->deepbrain) (2.5.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->deepbrain) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->deepbrain) (0.10.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.3.0->scikit-image->deepbrain) (0.46)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow->deepbrain) (0.15.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow->deepbrain) (3.1.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow->deepbrain) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow->deepbrain) (41.0.1)\n",
            "Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow->deepbrain) (3.0.5)\n",
            "Requirement already satisfied: pydicom in /usr/local/lib/python3.6/dist-packages (1.2.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vThwOxSsZcG",
        "colab_type": "code",
        "outputId": "2540f5ff-f192-4257-fdae-04dd19a6a2e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# mount google drive into google colab\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDPKsjxlsZvm",
        "colab_type": "code",
        "outputId": "1c85e1fa-b4e7-4450-bcad-302623280b57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "import os\n",
        "    \n",
        "# go to where the data is\n",
        "print (os.listdir())\n",
        "os.chdir('gdrive/My Drive/msc_project')\n",
        "os.listdir()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['.config', 'gdrive', 'sample_data']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['t1_scan',\n",
              " 'T1_SAG_SIEMEN_3T_CLEAN_5_29_2019.csv',\n",
              " 'T1_SAG_SIEMEN_3T_CLEAN_1',\n",
              " 'T1_SAG_SIEMEN_3T_CLEAN_5_29_2019.gsheet',\n",
              " 'T1_SAG_SIEMEN_3T_CLEAN',\n",
              " 'loaded_slices',\n",
              " 'processed_augmented_slices']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_Rz2-kfsp1i",
        "colab_type": "code",
        "outputId": "ea375908-bc4a-4db6-8ea6-d1e7ce663634",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "import pandas as pd\n",
        "# https://www.kaggle.com/sentdex/first-pass-through-data-w-3d-convnet\n",
        "patients_file_dir = 'T1_SAG_SIEMEN_3T_CLEAN'\n",
        "\n",
        "patients = os.listdir(patients_file_dir) # get all patients ID's in scan\n",
        "patient_df = pd.read_csv('T1_SAG_SIEMEN_3T_CLEAN_5_29_2019.csv') # get dataframe too to cross reference\n",
        "\n",
        "patient_df.head() # so we have a dataframe of our patients' data"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Image Data ID</th>\n",
              "      <th>Subject</th>\n",
              "      <th>Group</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>Visit</th>\n",
              "      <th>Modality</th>\n",
              "      <th>Description</th>\n",
              "      <th>Type</th>\n",
              "      <th>Acq Date</th>\n",
              "      <th>Format</th>\n",
              "      <th>Downloaded</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1130198</td>\n",
              "      <td>75422</td>\n",
              "      <td>GenCohort Unaff</td>\n",
              "      <td>M</td>\n",
              "      <td>73</td>\n",
              "      <td>1</td>\n",
              "      <td>MRI</td>\n",
              "      <td>MPRAGE GRAPPA</td>\n",
              "      <td>Original</td>\n",
              "      <td>11/13/2018</td>\n",
              "      <td>DCM</td>\n",
              "      <td>5/07/2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1130190</td>\n",
              "      <td>75414</td>\n",
              "      <td>GenCohort Unaff</td>\n",
              "      <td>F</td>\n",
              "      <td>73</td>\n",
              "      <td>1</td>\n",
              "      <td>MRI</td>\n",
              "      <td>Sag MPRAGE GRAPPA</td>\n",
              "      <td>Original</td>\n",
              "      <td>12/13/2018</td>\n",
              "      <td>DCM</td>\n",
              "      <td>4/24/2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1130191</td>\n",
              "      <td>75414</td>\n",
              "      <td>GenCohort Unaff</td>\n",
              "      <td>F</td>\n",
              "      <td>73</td>\n",
              "      <td>1</td>\n",
              "      <td>MRI</td>\n",
              "      <td>Sag MPRAGE GRAPPA</td>\n",
              "      <td>Original</td>\n",
              "      <td>12/13/2018</td>\n",
              "      <td>DCM</td>\n",
              "      <td>4/24/2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1125041</td>\n",
              "      <td>74375</td>\n",
              "      <td>GenCohort Unaff</td>\n",
              "      <td>F</td>\n",
              "      <td>59</td>\n",
              "      <td>1</td>\n",
              "      <td>MRI</td>\n",
              "      <td>MPRAGE_GRAPPA</td>\n",
              "      <td>Original</td>\n",
              "      <td>9/06/2018</td>\n",
              "      <td>DCM</td>\n",
              "      <td>4/24/2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1003469</td>\n",
              "      <td>72138</td>\n",
              "      <td>GenCohort Unaff</td>\n",
              "      <td>F</td>\n",
              "      <td>55</td>\n",
              "      <td>1</td>\n",
              "      <td>MRI</td>\n",
              "      <td>MPRAGE GRAPPA</td>\n",
              "      <td>Original</td>\n",
              "      <td>2/19/2018</td>\n",
              "      <td>DCM</td>\n",
              "      <td>4/24/2019</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Image Data ID  Subject            Group  ...    Acq Date  Format  Downloaded\n",
              "0        1130198    75422  GenCohort Unaff  ...  11/13/2018     DCM   5/07/2019\n",
              "1        1130190    75414  GenCohort Unaff  ...  12/13/2018     DCM   4/24/2019\n",
              "2        1130191    75414  GenCohort Unaff  ...  12/13/2018     DCM   4/24/2019\n",
              "3        1125041    74375  GenCohort Unaff  ...   9/06/2018     DCM   4/24/2019\n",
              "4        1003469    72138  GenCohort Unaff  ...   2/19/2018     DCM   4/24/2019\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12VGP3E9Cplw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Map GenCohort to regular PD and Controls\n",
        "patient_df['Group'] = patient_df['Group'].replace({'GenCohort PD':'PD', 'GenCohort Unaff':'Control'})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTxaWLyMviqi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_grappa_dir(path):\n",
        "  # get the file ending with 'GRAPPA', would need to accomodate this for grappa also\n",
        "  returning_path = None\n",
        "  for next_path in os.listdir(path):\n",
        "    if (next_path.split(\"_\")[-1] == 'GRAPPA'): # for the t1 weighted\n",
        "      returning_path = next_path\n",
        "      return returning_path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4smr-Q1y5td",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_dcm_s(path):\n",
        "  # get the path beginning with S, so doesn't clash with GZ File\n",
        "  for next_path in os.listdir(path):\n",
        "    if (next_path[0] == 'S'):\n",
        "      return next_path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W13cQHKlcER1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_img_no(path):\n",
        "  # get the image identification numberm any image will do for this so take first\n",
        "  image_number = None\n",
        "  for image_file in os.listdir(path):\n",
        "    image_number = int(image_file.split(\"_\")[-1][1:-4]) # index to get the ID\n",
        "   \n",
        "  return image_number"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJaXNmXjigRu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def filename_sort(filename):\n",
        "    \n",
        "    # split by underlines and delimiter\n",
        "    split_line = filename.split(\"_\")\n",
        "    int_return = int(split_line[-3])\n",
        "    \n",
        "    return int_return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjlKpUkxtEM8",
        "colab_type": "code",
        "outputId": "06fe68f5-aebe-4880-8b95-a09e20b461a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4469
        }
      },
      "source": [
        "import pydicom\n",
        "import numpy as np\n",
        "\n",
        "cwd = os.getcwd()\n",
        "print (\"Current Working Dir: %s \" % cwd)\n",
        "\n",
        "total_slices = [] # build all the slices\n",
        "counter = 0\n",
        "\n",
        "for patient in patients[:150]:\n",
        "  try:\n",
        "    # label = patient_df.get_value(patient, 'Subject') # cannot go by patient, must get the ID\n",
        "    path = cwd + '/' + patients_file_dir +'/' + patient # get to the GRAPPA \n",
        "    path = path + '/' + get_grappa_dir(path)\n",
        "    path = path + '/' + os.listdir(path)[-1] # get the most recent scan for patient\n",
        "    path = path + '/' + get_dcm_s(path)\n",
        "\n",
        "    # get information related around the image\n",
        "    image_number = get_img_no(path)\n",
        "    image_row = patient_df.loc[patient_df['Image Data ID'] == image_number] # relate to df\n",
        "    image_sex = image_row.Sex.values[0]\n",
        "    image_group = image_row.Group.values[0]\n",
        "    image_age = image_row.Age.values[0]\n",
        "\n",
        "    # create image object and append to total info\n",
        "    image_info = [image_number, image_sex, image_group, image_age]\n",
        "\n",
        "    # print (\"Sex: %s, Age: %s, Group: %s \" % (image_sex, image_age, image_group))\n",
        "\n",
        "    # get files and sort them in order\n",
        "    dcm_files = os.listdir(path)\n",
        "    dcm_files = sorted(dcm_files, key=lambda filename: filename_sort(filename)) # some have length 3\n",
        "\n",
        "    slices = []\n",
        "    # loop through slices and build the array\n",
        "    for dcm_file in dcm_files:\n",
        "      path_to_file = path + '/' + dcm_file\n",
        "      slices.append(pydicom.read_file(path_to_file).pixel_array)\n",
        "    slices = np.array(slices)[15:175, :, :]\n",
        "    \n",
        "    if (np.shape(slices)[0] == 160): # only add if slices are 160\n",
        "      total_slices.append([slices, image_info])\n",
        "    \n",
        "      # print for counter\n",
        "      counter = counter+1\n",
        "      print (\"%d slices loaded\" % counter)\n",
        "\n",
        "      print (np.shape(slices)) # each patient has different number of slices, trim it to [15:175, 30:230, 30:230]\n",
        " \n",
        "  except Exception as e:\n",
        "    print (\"No File Found: %s\" % str(e))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Current Working Dir: /content/gdrive/My Drive/msc_project \n",
            "1 slices loaded\n",
            "(160, 256, 240)\n",
            "2 slices loaded\n",
            "(160, 256, 240)\n",
            "3 slices loaded\n",
            "(160, 256, 240)\n",
            "4 slices loaded\n",
            "(160, 256, 240)\n",
            "5 slices loaded\n",
            "(160, 256, 240)\n",
            "6 slices loaded\n",
            "(160, 256, 240)\n",
            "7 slices loaded\n",
            "(160, 256, 240)\n",
            "8 slices loaded\n",
            "(160, 256, 240)\n",
            "9 slices loaded\n",
            "(160, 256, 240)\n",
            "10 slices loaded\n",
            "(160, 256, 240)\n",
            "11 slices loaded\n",
            "(160, 256, 240)\n",
            "12 slices loaded\n",
            "(160, 256, 240)\n",
            "13 slices loaded\n",
            "(160, 256, 240)\n",
            "14 slices loaded\n",
            "(160, 256, 240)\n",
            "15 slices loaded\n",
            "(160, 256, 240)\n",
            "16 slices loaded\n",
            "(160, 256, 240)\n",
            "17 slices loaded\n",
            "(160, 256, 240)\n",
            "18 slices loaded\n",
            "(160, 256, 240)\n",
            "19 slices loaded\n",
            "(160, 256, 240)\n",
            "20 slices loaded\n",
            "(160, 256, 240)\n",
            "21 slices loaded\n",
            "(160, 256, 240)\n",
            "22 slices loaded\n",
            "(160, 256, 240)\n",
            "23 slices loaded\n",
            "(160, 256, 240)\n",
            "24 slices loaded\n",
            "(160, 256, 240)\n",
            "25 slices loaded\n",
            "(160, 256, 240)\n",
            "26 slices loaded\n",
            "(160, 256, 240)\n",
            "27 slices loaded\n",
            "(160, 256, 240)\n",
            "28 slices loaded\n",
            "(160, 256, 240)\n",
            "29 slices loaded\n",
            "(160, 256, 240)\n",
            "30 slices loaded\n",
            "(160, 256, 240)\n",
            "31 slices loaded\n",
            "(160, 256, 240)\n",
            "32 slices loaded\n",
            "(160, 256, 240)\n",
            "33 slices loaded\n",
            "(160, 256, 240)\n",
            "34 slices loaded\n",
            "(160, 256, 240)\n",
            "35 slices loaded\n",
            "(160, 256, 240)\n",
            "36 slices loaded\n",
            "(160, 256, 240)\n",
            "37 slices loaded\n",
            "(160, 256, 240)\n",
            "38 slices loaded\n",
            "(160, 256, 240)\n",
            "39 slices loaded\n",
            "(160, 256, 240)\n",
            "40 slices loaded\n",
            "(160, 256, 240)\n",
            "41 slices loaded\n",
            "(160, 256, 240)\n",
            "42 slices loaded\n",
            "(160, 256, 240)\n",
            "43 slices loaded\n",
            "(160, 256, 240)\n",
            "44 slices loaded\n",
            "(160, 256, 240)\n",
            "45 slices loaded\n",
            "(160, 256, 240)\n",
            "46 slices loaded\n",
            "(160, 256, 240)\n",
            "47 slices loaded\n",
            "(160, 256, 240)\n",
            "48 slices loaded\n",
            "(160, 256, 240)\n",
            "49 slices loaded\n",
            "(160, 256, 240)\n",
            "50 slices loaded\n",
            "(160, 256, 240)\n",
            "51 slices loaded\n",
            "(160, 256, 240)\n",
            "52 slices loaded\n",
            "(160, 256, 240)\n",
            "53 slices loaded\n",
            "(160, 256, 240)\n",
            "54 slices loaded\n",
            "(160, 256, 240)\n",
            "55 slices loaded\n",
            "(160, 256, 240)\n",
            "56 slices loaded\n",
            "(160, 256, 240)\n",
            "57 slices loaded\n",
            "(160, 256, 240)\n",
            "58 slices loaded\n",
            "(160, 256, 240)\n",
            "59 slices loaded\n",
            "(160, 256, 240)\n",
            "60 slices loaded\n",
            "(160, 256, 240)\n",
            "61 slices loaded\n",
            "(160, 256, 240)\n",
            "62 slices loaded\n",
            "(160, 256, 240)\n",
            "63 slices loaded\n",
            "(160, 256, 240)\n",
            "64 slices loaded\n",
            "(160, 256, 240)\n",
            "65 slices loaded\n",
            "(160, 256, 240)\n",
            "66 slices loaded\n",
            "(160, 256, 240)\n",
            "67 slices loaded\n",
            "(160, 256, 240)\n",
            "68 slices loaded\n",
            "(160, 256, 240)\n",
            "69 slices loaded\n",
            "(160, 256, 240)\n",
            "70 slices loaded\n",
            "(160, 256, 240)\n",
            "71 slices loaded\n",
            "(160, 256, 240)\n",
            "72 slices loaded\n",
            "(160, 256, 240)\n",
            "73 slices loaded\n",
            "(160, 256, 240)\n",
            "74 slices loaded\n",
            "(160, 256, 240)\n",
            "75 slices loaded\n",
            "(160, 256, 240)\n",
            "76 slices loaded\n",
            "(160, 256, 256)\n",
            "No File Found: must be str, not NoneType\n",
            "77 slices loaded\n",
            "(160, 256, 240)\n",
            "No File Found: must be str, not NoneType\n",
            "No File Found: must be str, not NoneType\n",
            "78 slices loaded\n",
            "(160, 256, 240)\n",
            "No File Found: must be str, not NoneType\n",
            "No File Found: must be str, not NoneType\n",
            "No File Found: must be str, not NoneType\n",
            "79 slices loaded\n",
            "(160, 256, 256)\n",
            "No File Found: must be str, not NoneType\n",
            "80 slices loaded\n",
            "(160, 256, 256)\n",
            "No File Found: must be str, not NoneType\n",
            "No File Found: must be str, not NoneType\n",
            "No File Found: must be str, not NoneType\n",
            "No File Found: must be str, not NoneType\n",
            "81 slices loaded\n",
            "(160, 256, 256)\n",
            "No File Found: must be str, not NoneType\n",
            "No File Found: must be str, not NoneType\n",
            "82 slices loaded\n",
            "(160, 256, 256)\n",
            "83 slices loaded\n",
            "(160, 256, 240)\n",
            "84 slices loaded\n",
            "(160, 256, 240)\n",
            "85 slices loaded\n",
            "(160, 256, 256)\n",
            "86 slices loaded\n",
            "(160, 256, 240)\n",
            "87 slices loaded\n",
            "(160, 256, 240)\n",
            "88 slices loaded\n",
            "(160, 256, 240)\n",
            "89 slices loaded\n",
            "(160, 256, 240)\n",
            "90 slices loaded\n",
            "(160, 256, 240)\n",
            "91 slices loaded\n",
            "(160, 256, 240)\n",
            "92 slices loaded\n",
            "(160, 256, 240)\n",
            "93 slices loaded\n",
            "(160, 256, 240)\n",
            "94 slices loaded\n",
            "(160, 256, 240)\n",
            "95 slices loaded\n",
            "(160, 256, 240)\n",
            "96 slices loaded\n",
            "(160, 256, 240)\n",
            "97 slices loaded\n",
            "(160, 256, 240)\n",
            "98 slices loaded\n",
            "(160, 256, 240)\n",
            "99 slices loaded\n",
            "(160, 256, 240)\n",
            "100 slices loaded\n",
            "(160, 256, 240)\n",
            "101 slices loaded\n",
            "(160, 256, 240)\n",
            "102 slices loaded\n",
            "(160, 256, 240)\n",
            "103 slices loaded\n",
            "(160, 256, 240)\n",
            "104 slices loaded\n",
            "(160, 256, 240)\n",
            "105 slices loaded\n",
            "(160, 256, 240)\n",
            "106 slices loaded\n",
            "(160, 256, 240)\n",
            "107 slices loaded\n",
            "(160, 256, 240)\n",
            "108 slices loaded\n",
            "(160, 256, 240)\n",
            "109 slices loaded\n",
            "(160, 256, 240)\n",
            "110 slices loaded\n",
            "(160, 256, 240)\n",
            "111 slices loaded\n",
            "(160, 256, 240)\n",
            "112 slices loaded\n",
            "(160, 256, 240)\n",
            "113 slices loaded\n",
            "(160, 256, 256)\n",
            "114 slices loaded\n",
            "(160, 256, 240)\n",
            "115 slices loaded\n",
            "(160, 256, 240)\n",
            "No File Found: must be str, not NoneType\n",
            "116 slices loaded\n",
            "(160, 256, 240)\n",
            "No File Found: must be str, not NoneType\n",
            "117 slices loaded\n",
            "(160, 256, 240)\n",
            "118 slices loaded\n",
            "(160, 256, 240)\n",
            "No File Found: must be str, not NoneType\n",
            "119 slices loaded\n",
            "(160, 256, 248)\n",
            "No File Found: must be str, not NoneType\n",
            "No File Found: must be str, not NoneType\n",
            "No File Found: must be str, not NoneType\n",
            "No File Found: must be str, not NoneType\n",
            "No File Found: must be str, not NoneType\n",
            "No File Found: must be str, not NoneType\n",
            "No File Found: must be str, not NoneType\n",
            "No File Found: must be str, not NoneType\n",
            "No File Found: must be str, not NoneType\n",
            "No File Found: must be str, not NoneType\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEvRuoutTYOv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0Um7yP1Qpw1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save the loaded slices\n",
        "with open('loaded_slices', \"wb\") as f:\n",
        "    pickle.dump(total_slices, f)   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdeJlFycRjg2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load our slices\n",
        "total_slices = pickle.load( open( \"loaded_slices\", \"rb\" ) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Aw3M48BuCvj",
        "colab_type": "code",
        "outputId": "db787b1e-354b-4bde-efc3-89ddaf325961",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4086
        }
      },
      "source": [
        "from deepbrain import Extractor\n",
        "import nibabel as nb\n",
        "\n",
        "total_slices_processed = []\n",
        "slice_info = []\n",
        "\n",
        "for total_slice in total_slices:\n",
        "  # deal with mixed slice information\n",
        "  slices = total_slice[0]\n",
        "  slice_info.append(total_slice[1])\n",
        "  \n",
        "  # transform into axial view\n",
        "  slice_axial = slices.transpose((1,2,0))\n",
        "  \n",
        "  # initialise skull stripper\n",
        "  ext = Extractor()\n",
        "\n",
        "  # get probability of part of image being brain tissue or not\n",
        "  prob = ext.run(slice_axial)\n",
        "  mask = prob > 1e-3 # mask can be obtained as:\n",
        "  slice_axial[~mask] = 0 # apply mask\n",
        "  \n",
        "  slice_axial = slice_axial[30:230, 30:230, :] # trim blank ones\n",
        "  total_slices_processed.append(slice_axial) # add original\n",
        "  \n",
        "  # flip images and add to total processed arrays\n",
        "  flipped_slices = [np.flip(sl,1) for sl in slice_axial]\n",
        "  total_slices_processed.append(flipped_slices)\n",
        "  slice_info.append(total_slice[1]) # add info twice\n",
        "    \n",
        "  print (\"Regular Shape: %s \" % (np.shape(slice_axial), ))\n",
        "  print (\"Flipped Shape: %s \" % (np.shape(flipped_slices), ))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deepbrain/extractor.py:19: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.gfile.GFile.\n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n",
            "Regular Shape: (200, 200, 160) \n",
            "Flipped Shape: (200, 200, 160) \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2f2Eu3iV2Lws",
        "colab_type": "code",
        "outputId": "699b2176-5573-4891-ac9d-a370065651f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "total_slices_processed = np.array(total_slices_processed) # turn into array\n",
        "total_slices_processed = np.expand_dims(total_slices_processed, axis=4) # expand dimensions\n",
        "\n",
        "np.shape(total_slices_processed)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(238, 200, 200, 160, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hZTuCRnAiUz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# need to build the y-data set (PD or Healthy)\n",
        "# then split into test and training set\n",
        "# then try run through a basic model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUTUGaL3Ku3t",
        "colab_type": "code",
        "outputId": "9395d05d-2dfc-49bb-ead3-0c0efdf91e86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4032
        }
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "# build y-outputs\n",
        "diagnosis = [s[2] for s in slice_info] # we got our y-values\n",
        "diagnosis = [1 if s=='PD' else s for s in diagnosis]\n",
        "diagnosis = [0 if s=='Control' else s for s in diagnosis]\n",
        "\n",
        "y_output = to_categorical(diagnosis, 2) # convert to something categorical with keras util\n",
        "y_output = np.array(y_output)\n",
        "\n",
        "print (y_output)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxElWmE4SbU7",
        "colab_type": "code",
        "outputId": "ad4c84f4-715a-477e-8714-04d52b3dc318",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# split into training and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(total_slices_processed, y_output, test_size=0.2, shuffle=True)\n",
        "\n",
        "np.shape(X_train)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(190, 200, 200, 160, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQKeVRq-Uowv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers.convolutional import Convolution3D, MaxPooling3D\n",
        "from keras.optimizers import SGD, RMSprop, Adam\n",
        "from keras.utils import np_utils, generic_utils\n",
        "from keras.layers import LeakyReLU"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjXpitscUqMu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "130bf23d-e52e-479b-b01c-a5174ca75e23"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Convolution3D(filters=8, kernel_size=2, strides=1, \n",
        "                        padding='same', input_shape=(200,200,160,1))) # or should activation be linear?\n",
        "model.add(LeakyReLU(alpha=0.01)) # set to 0.01\n",
        "model.add(MaxPooling3D())\n",
        "\n",
        "model.add(Convolution3D(filters=16, kernel_size=2, strides=1, \n",
        "                        padding='same'))\n",
        "model.add(LeakyReLU(alpha=0.01)) \n",
        "model.add(MaxPooling3D())\n",
        "\n",
        "model.add(Convolution3D(filters=32, kernel_size=3, strides=1, \n",
        "                        padding='same'))\n",
        "model.add(LeakyReLU(alpha=0.01))\n",
        "model.add(MaxPooling3D())\n",
        "\n",
        "model.add(Convolution3D(filters=64, kernel_size=3, strides=1, \n",
        "                        padding='same'))\n",
        "model.add(LeakyReLU(alpha=0.01))\n",
        "model.add(MaxPooling3D())\n",
        "\n",
        "model.add(Convolution3D(filters=128, kernel_size=4, strides=1, \n",
        "                        padding='same'))\n",
        "model.add(LeakyReLU(alpha=0.01))\n",
        "model.add(MaxPooling3D())\n",
        "\n",
        "model.add(Convolution3D(filters=256, kernel_size=4, strides=1, \n",
        "                        padding='same'))\n",
        "model.add(LeakyReLU(alpha=0.01))\n",
        "model.add(MaxPooling3D())\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(1024))\n",
        "model.add(LeakyReLU(alpha=0.01))\n",
        "\n",
        "model.add(Dense(2))\n",
        "\n",
        "model.compile(optimizer=Adam(lr=0.00005), loss='categorical_crossentropy',metrics = ['categorical_accuracy']) # metrics=['categorical_accuracy']"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiAHKsHu60Zd",
        "colab_type": "code",
        "outputId": "cd592ed7-467b-4542-ccea-71db71aa8166",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 890
        }
      },
      "source": [
        "# optimising with: https://towardsdatascience.com/hyperparameter-optimization-with-keras-b82e6364ca53\n",
        "print (model.summary())"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv3d_1 (Conv3D)            (None, 200, 200, 160, 8)  72        \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 200, 200, 160, 8)  0         \n",
            "_________________________________________________________________\n",
            "max_pooling3d_1 (MaxPooling3 (None, 100, 100, 80, 8)   0         \n",
            "_________________________________________________________________\n",
            "conv3d_2 (Conv3D)            (None, 100, 100, 80, 16)  1040      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 100, 100, 80, 16)  0         \n",
            "_________________________________________________________________\n",
            "max_pooling3d_2 (MaxPooling3 (None, 50, 50, 40, 16)    0         \n",
            "_________________________________________________________________\n",
            "conv3d_3 (Conv3D)            (None, 50, 50, 40, 32)    13856     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 50, 50, 40, 32)    0         \n",
            "_________________________________________________________________\n",
            "max_pooling3d_3 (MaxPooling3 (None, 25, 25, 20, 32)    0         \n",
            "_________________________________________________________________\n",
            "conv3d_4 (Conv3D)            (None, 25, 25, 20, 64)    55360     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 25, 25, 20, 64)    0         \n",
            "_________________________________________________________________\n",
            "max_pooling3d_4 (MaxPooling3 (None, 12, 12, 10, 64)    0         \n",
            "_________________________________________________________________\n",
            "conv3d_5 (Conv3D)            (None, 12, 12, 10, 128)   524416    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)    (None, 12, 12, 10, 128)   0         \n",
            "_________________________________________________________________\n",
            "max_pooling3d_5 (MaxPooling3 (None, 6, 6, 5, 128)      0         \n",
            "_________________________________________________________________\n",
            "conv3d_6 (Conv3D)            (None, 6, 6, 5, 256)      2097408   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)    (None, 6, 6, 5, 256)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling3d_6 (MaxPooling3 (None, 3, 3, 2, 256)      0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 4608)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1024)              4719616   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)    (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2)                 2050      \n",
            "=================================================================\n",
            "Total params: 7,413,818\n",
            "Trainable params: 7,413,818\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPrbqZh7FNqh",
        "colab_type": "code",
        "outputId": "a8e93612-830b-4260-9a33-39c496f9badb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        }
      },
      "source": [
        "model.fit(x=X_train, y=y_train, batch_size=10, epochs=5, verbose=1,\n",
        "          validation_data=(X_test, y_test), shuffle=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-76baa782fb53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model.fit(x=X_train, y=y_train, batch_size=10, epochs=5, verbose=1,\n\u001b[0m\u001b[1;32m      2\u001b[0m           validation_data=(X_test, y_test), shuffle=True)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2taENt9fd5f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save the trained models to evaluate in future (with validation set?)\n",
        "with open('trained_model', \"wb\") as f:\n",
        "    pickle.dump(model, f)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXqdPjxVghsu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load our model\n",
        "total_slices = pickle.load( open( \"trained_model\", \"rb\" ) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1H__27JiltF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "8f72b6ae-20b2-4572-c074-f8255d43732b"
      },
      "source": [
        "# https://github.com/MinhazPalasara/keras/blob/master/examples/shapes_3d_cnn.py\n",
        "score = model.evaluate(X_test, y_test, batch_size=None)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-4933c5afc4b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test score:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test accuracy:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flSVXwCCnz_S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.shape(np.squeeze(total_slices_processed, axis=4))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4IfnRuglX2K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from ipywidgets import interact, interactive, fixed, interact_manual\n",
        "import ipywidgets as widgets # interactive plots\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "total_slices_processed = np.squeeze(total_slices_processed, axis=4)\n",
        "def g(i): # basic slideshow plot to get an idea of the effectiveness of the mask itself\n",
        "    plt.figure(figsize=(15,8)) # make plot larger\n",
        "    plt.imshow(total_slices_processed[1][i])\n",
        "    plt.show()\n",
        "    return None\n",
        "  \n",
        "interact(g, i=widgets.IntSlider(min=0,max=(len(total_slices_processed[1])-1),step=1,value=65)); # plots our axial view, this is it"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHNUj5XQs-0L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}